{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tempfile\n",
    "import os\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load custom YOLO model for object detection and pose estimation\n",
    "custom_model = YOLO(r\"C:\\Users\\anuma\\OneDrive\\Desktop\\data science\\project_1\\pratice_code\\best.pt\")  # Replace with your trained model path\n",
    "pose_model = YOLO(\"yolov8n-pose.pt\")  # YOLOv8 Pose Estimation Model\n",
    "\n",
    "# Function to calculate angles between three points\n",
    "def calculate_angle(a, b, c):\n",
    "    a, b, c = np.array(a), np.array(b), np.array(c)\n",
    "    ba, bc = a - b, c - b\n",
    "    cosine_angle = np.dot(ba, bc) / (np.linalg.norm(ba) * np.linalg.norm(bc))\n",
    "    return np.degrees(np.arccos(np.clip(cosine_angle, -1.0, 1.0)))\n",
    "\n",
    "# Function to classify poses\n",
    "def classify_pose(keypoints, frame_height):\n",
    "    if keypoints is None or len(keypoints) < 17:\n",
    "        return [\"Unknown\"]\n",
    "\n",
    "    nose, left_eye, right_eye, left_ear, right_ear = keypoints[:5]\n",
    "    left_shoulder, right_shoulder, left_elbow, right_elbow = keypoints[5:9]\n",
    "    left_wrist, right_wrist, left_hip, right_hip = keypoints[9:13]\n",
    "    left_knee, right_knee, left_ankle, right_ankle = keypoints[13:17]\n",
    "\n",
    "    detected_actions = []\n",
    "    \n",
    "    # Calculate key angles\n",
    "    left_arm_angle = calculate_angle(left_hip, left_shoulder, left_elbow)\n",
    "    right_arm_angle = calculate_angle(right_hip, right_shoulder, right_elbow)\n",
    "    bending_angle = calculate_angle(left_shoulder, left_hip, left_knee)\n",
    "    leaning_angle = calculate_angle(left_shoulder, right_shoulder, right_hip)\n",
    "    climbing_angle = calculate_angle(left_elbow, left_knee, left_ankle)\n",
    "    left_leg_angle = calculate_angle(left_hip, left_knee, left_ankle)\n",
    "    right_leg_angle = calculate_angle(right_hip, right_knee, right_ankle)\n",
    "\n",
    "    # Detect Bending\n",
    "    if bending_angle < 100:\n",
    "        detected_actions.append(\"Bending\")\n",
    "    \n",
    "    # Detect arm raising\n",
    "    if left_arm_angle > 50:\n",
    "        detected_actions.append(\"Left Arm Raised\")\n",
    "    if right_arm_angle > 50:\n",
    "        detected_actions.append(\"Right Arm Raised\")\n",
    "\n",
    "    # Detect Running (based on knee height difference)\n",
    "    if ((110 <= left_leg_angle <= 170 and right_knee[1] < left_knee[1]) or\n",
    "        (110 <= right_leg_angle <= 170 and left_knee[1] < right_knee[1])) and \\\n",
    "        (50 <= left_arm_angle <= 140 or 50 <= right_arm_angle <= 140):\n",
    "        detected_actions.append(\"Running\")\n",
    "\n",
    "    # Detect Lying on the Floor (if hips are close to the ground)\n",
    "    hip_avg_y = (left_hip[1] + right_hip[1]) / 2\n",
    "    shoulder_avg_y = (left_shoulder[1] + right_shoulder[1]) / 2\n",
    "    if hip_avg_y < 0.8 * frame_height and shoulder_avg_y < 0.8 * frame_height:\n",
    "        detected_actions.append(\"Lying on the Floor\")\n",
    "\n",
    "    # Detect Touching Face (if wrist is close to face)\n",
    "    if (np.linalg.norm(left_wrist - nose) < 50 or np.linalg.norm(right_wrist - nose) < 50 or\n",
    "       np.linalg.norm(left_wrist - left_eye) < 50 or np.linalg.norm(right_wrist - right_eye) < 50 or\n",
    "       np.linalg.norm(left_wrist - left_ear) < 50 or np.linalg.norm(right_wrist - right_ear) < 50):\n",
    "        detected_actions.append(\"Touching Face\")\n",
    "\n",
    "    # Detect Jumping (if ankles are above normal position)\n",
    "    if left_ankle[1] > 0.1 * frame_height and right_ankle[1] > 0.1 * frame_height:\n",
    "        detected_actions.append(\"Jumping\")\n",
    "\n",
    "    # Detect Leaning\n",
    "    if leaning_angle < 80:\n",
    "        detected_actions.append(\"Leaning Forward\")\n",
    "    elif leaning_angle > 100:\n",
    "        detected_actions.append(\"Leaning Backward\")\n",
    "\n",
    "    # Detect Climbing\n",
    "    if climbing_angle < 100 and abs(left_knee[1] - left_hip[1]) > 50:\n",
    "        detected_actions.append(\"Climbing\")\n",
    "\n",
    "    return detected_actions if detected_actions else [\"Standing\"]\n",
    "\n",
    "# Function to process video\n",
    "def process_video(video_path, output_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_width = int(cap.get(3))\n",
    "    frame_height = int(cap.get(4))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "    stframe = st.empty()  # Placeholder for video display\n",
    "    action_text = st.empty()  # Placeholder for detected actions\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Run object detection\n",
    "        obj_results = custom_model(frame)\n",
    "        frame_with_boxes = obj_results[0].plot()  # Draw bounding boxes\n",
    "\n",
    "        # Run pose estimation\n",
    "        pose_results = pose_model(frame_with_boxes)\n",
    "\n",
    "        for result in pose_results:\n",
    "            if hasattr(result, \"keypoints\") and result.keypoints is not None:\n",
    "                keypoints = result.keypoints.xy.cpu().numpy()\n",
    "                \n",
    "                for kp in keypoints:\n",
    "                    actions = classify_pose(kp, frame_height)\n",
    "\n",
    "                    # Display action text on video\n",
    "                    y_offset = 50\n",
    "                    for action in actions:\n",
    "                        cv2.putText(frame_with_boxes, action, (50, y_offset), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "                        y_offset += 40\n",
    "\n",
    "                    # Draw keypoints\n",
    "                    for x, y in kp:\n",
    "                        cv2.circle(frame_with_boxes, (int(x), int(y)), 5, (0, 255, 0), -1)\n",
    "\n",
    "                    action_text.text(f\"Detected Actions: {', '.join(actions)}\")\n",
    "\n",
    "        out.write(frame_with_boxes)\n",
    "\n",
    "        # Convert to RGB for Streamlit\n",
    "        frame_rgb = cv2.cvtColor(frame_with_boxes, cv2.COLOR_BGR2RGB)\n",
    "        stframe.image(frame_rgb, channels=\"RGB\")\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "\n",
    "# Streamlit UI\n",
    "st.title(\"YOLO Object Detection & Pose Estimation ðŸŽ¥\")\n",
    "\n",
    "uploaded_file = st.file_uploader(\"Upload a video\", type=[\"mp4\", \"avi\", \"mov\"])\n",
    "\n",
    "if uploaded_file:\n",
    "    with st.spinner(\"Processing video... Please wait.\"):\n",
    "        tfile = tempfile.NamedTemporaryFile(delete=False)\n",
    "        tfile.write(uploaded_file.read())\n",
    "        video_path = tfile.name\n",
    "        output_path = \"output_video.mp4\"\n",
    "\n",
    "        process_video(video_path, output_path)  # Process video\n",
    "\n",
    "        # Cleanup temp file\n",
    "        st.success(\"Processing completed!\")\n",
    "\n",
    "        with open(output_path, \"rb\") as file:\n",
    "            st.download_button(label=\"Download Processed Video ðŸŽ¬\", data=file, file_name=\"output_video.mp4\", mime=\"video/mp4\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
